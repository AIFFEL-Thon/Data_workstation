{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5873ef-8da8-4556-8e37-fcf0ce842a5c",
   "metadata": {},
   "source": [
    "# 1. Pragmatic Ambiguous Sentences Dataset\r\n",
    "- Extraction information of each Utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57bc58b-f4dc-47f1-bc2b-be0a5231409a",
   "metadata": {},
   "source": [
    "## 2) Extract emotion labeles from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64470def-d036-420b-bff5-54f86d517c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d6d186f7-f0cc-4a65-8fd6-3d886d2e4c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_objects(unit_folder, json_path):\n",
    "    \"\"\"\n",
    "    1) JSON 파일 로드\n",
    "    2) data[frame_no][object_id] 순회\n",
    "    3) object_id in [1, 2], label='person', text 필드 존재 시\n",
    "       - frame, predicate, emotion, label, text 내 script, script_start, script_end, intent, strategy, morpheme\n",
    "       - person_id\n",
    "       - emotion 내 각 (valence, emotion, arousal) for image, sound, multimodal, text\n",
    "    4) 결과를 (dict) 리스트 형태로 반환\n",
    "    \"\"\"\n",
    "\n",
    "    records = []\n",
    "    seen_text_triples = set()  # (script, script_start, script_end) 중복 체크용 집합\n",
    "\n",
    "    if not os.path.isfile(json_path):\n",
    "        print(f\"[스킵] 파일 없음: {json_path}\")\n",
    "        return records\n",
    "\n",
    "    try:\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"[에러] UTF-8로 디코딩할 수 없는 파일입니다: {json_path} - {str(e)}\")\n",
    "        return records\n",
    "\n",
    "    # data 필드 (프레임별 객체)\n",
    "    frame_dict = data.get(\"data\", {})\n",
    "    n_record = 0\n",
    "    for frame_no, obj_dict in frame_dict.items():\n",
    "        # obj_dict: 각 object_id -> object_info\n",
    "        for object_id, info in obj_dict.items():\n",
    "            # object_id가 '1' 또는 '2'만 추출 (문자열이므로 int 변환 후 비교 가능)\n",
    "            try:\n",
    "                obj_id_int = int(object_id)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if obj_id_int not in [1, 2]:\n",
    "                continue\n",
    "\n",
    "            # label이 \"person\"인지 확인\n",
    "            label = info.get(\"label\", \"\")  # .lower()\n",
    "            if label != \"사람\" and label != \"person\":\n",
    "                continue\n",
    "\n",
    "            # text 필드가 존재하는지 확인\n",
    "            text_info = info.get(\"text\", None)\n",
    "            if not text_info:\n",
    "                # text가 없으면 스킵\n",
    "                continue\n",
    "            \n",
    "            # text 필드\n",
    "            script = text_info.get(\"script\", None)\n",
    "            script_start = text_info.get(\"script_start\", None) # 시작 프레임 \n",
    "            script_end = text_info.get(\"script_end\", None)  # 종료 프레임             \n",
    "            \n",
    "            # (script, script_start, script_end) 중복 확인\n",
    "            text_key = (script, script_start, script_end)\n",
    "            if text_key in seen_text_triples:\n",
    "                # 이미 동일한 텍스트 구간이 기록되었다면 스킵\n",
    "                continue\n",
    "            seen_text_triples.add(text_key)\n",
    "            n_record += 1\n",
    "\n",
    "            intent = text_info.get(\"intent\", None)\n",
    "            strategy = text_info.get(\"strategy\", None)\n",
    "            morpheme = text_info.get(\"morpheme\", None)  # 텍스트 인코더 입력 고려하여 남김 \n",
    "            \n",
    "            # data 객체 층위, 필요한 필드 추출\n",
    "            clip_id = data.get(\"clip_id\", None)\n",
    "            actor = data.get(\"actor\", None)\n",
    "            situation = data.get(\"situation\", None)\n",
    "            category = data.get(\"category\", None)\n",
    "            nr_frame = data.get(\"nr_frame\", None)  # 전체 프레임 수\n",
    "            predicate = info.get(\"predicate\", {})\n",
    "            emotion = info.get(\"emotion\", {})\n",
    "            person_id = info.get(\"person_id\", None)\n",
    "            # emotion \n",
    "            # (image/sound/multimodal/text 중 image 제외한 각각의 valence, emotion, arousal)\n",
    "            sound_emo = emotion.get(\"sound\", {})\n",
    "            multi_emo = emotion.get(\"multimodal\", {})\n",
    "            text_emo = emotion.get(\"text\", {})\n",
    "            # (emotion, valence, arousal) 추출\n",
    "            sound_emotion = sound_emo.get(\"emotion\", None)\n",
    "            sound_valence = sound_emo.get(\"valence\", None)\n",
    "            sound_arousal = sound_emo.get(\"arousal\", None)\n",
    "            multimodal_emotion = multi_emo.get(\"emotion\", None)\n",
    "            multimodal_valence = multi_emo.get(\"valence\", None)\n",
    "            multimodal_arousal = multi_emo.get(\"arousal\", None)\n",
    "            text_emotion = text_emo.get(\"emotion\", None)\n",
    "            text_valence = text_emo.get(\"valence\", None)\n",
    "            text_arousal = text_emo.get(\"arousal\", None)\n",
    "\n",
    "            # record 생성\n",
    "            file_index = f'{unit_folder}_{clip_id}_{n_record}'\n",
    "            record = {\n",
    "                \"file_index\": file_index,\n",
    "                \"clip_id\": clip_id,\n",
    "                \"actor\": actor, \n",
    "                \"category\": category,\n",
    "                \"nr_frame\": nr_frame,                  \n",
    "                \"frame\": frame_no,\n",
    "                \"object_id\": object_id,\n",
    "                \"label\": label,\n",
    "                \"predicate\": predicate,   # dict로 저장\n",
    "                \"person_id\": person_id,\n",
    "                # text info\n",
    "                \"script\": script,\n",
    "                \"script_start\": script_start,\n",
    "                \"script_end\": script_end,\n",
    "                \"intent\": intent,\n",
    "                \"strategy\": strategy,\n",
    "                \"morpheme\": morpheme,\n",
    "                # emotion - sound\n",
    "                \"sound_valence\": sound_valence,\n",
    "                \"sound_emotion\": sound_emotion,\n",
    "                \"sound_arousal\": sound_arousal,\n",
    "                # emotion - multimodal\n",
    "                \"multimodal_valence\": multimodal_valence,\n",
    "                \"multimodal_emotion\": multimodal_emotion,\n",
    "                \"multimodal_arousal\": multimodal_arousal,\n",
    "                # emotion - text\n",
    "                \"text_valence\": text_valence,\n",
    "                \"text_emotion\": text_emotion,\n",
    "                \"text_arousal\": text_arousal\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2430cec7-33e4-4c38-833c-38ab891c66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_json(input_data_root_dir, output_path, list_unit_folder, clip_range):\n",
    "    all_dfs = []\n",
    "    for i, unit_name in enumerate(list_unit_folder):\n",
    "        for clip_id in range(clip_range[i][0], clip_range[i][1]):  # for clip_id in range(1, 401):\n",
    "            clip_folder = f\"clip_{clip_id}\"\n",
    "            input_path = os.path.join(input_data_root_dir, unit_name, clip_folder)\n",
    "            if not os.path.isdir(input_path):\n",
    "                print(f\"[스킵] 폴더 없음: {input_path}\")\n",
    "                continue\n",
    "            json_path = os.path.join(input_path, f\"clip_{clip_id}.json\")   \n",
    "            if not os.path.isfile(json_path):\n",
    "                print(f\"[스킵] JSON 파일 없음: {json_path}\")\n",
    "                continue\n",
    "            data_records = parse_json_objects(unit_name, json_path)\n",
    "            if not data_records:\n",
    "                print(f\"[완료] 발화 구간 없음: clip_{clip_id}\")\n",
    "                continue\n",
    "            df = pd.DataFrame(data_records)\n",
    "            df[\"unit_folder\"] = unit_name\n",
    "            print(f\"[INFO] clip_{clip_id} -> 총 {len(df)}개 발화 구간 레코드 dataframe이 저장되었습니다.\")\n",
    "            all_dfs.append(df)  # 400개 clip의 df 저장  \n",
    "        df_all_data = pd.concat(all_dfs, ignore_index=True)\n",
    "        unit_dfs = df_all_data[df_all_data[\"unit_folder\"] == unit_name].copy()\n",
    "        save_path = os.path.join(output_path, f'{unit_name}.csv')\n",
    "        unit_dfs.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"[INFO] 400개 clip의 CSV 파일이 저장되었습니다: {save_path}\")\n",
    "    \n",
    "    if not all_dfs:\n",
    "        print(\"[INFO] 처리할 데이터가 없습니다.\")\n",
    "        return None\n",
    "    df_all_data = pd.concat(all_dfs, ignore_index=True)\n",
    "    merged_filename = \"merged_data.csv\"\n",
    "    save_path = os.path.join(output_path, merged_filename)\n",
    "    df_all_data.to_csv(save_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[INFO] 모든 DataFrame이 합쳐진 CSV 파일이 저장되었습니다: {save_path}\")\n",
    "    \n",
    "    return df_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3a33e003-c3b1-4499-8a9c-7c9275c2e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_root_dir = 'G:/내 드라이브/aiffel/aiffelthon/multimodal/멀티모달 영상'\n",
    "output_path = 'G:/내 드라이브/aiffel/aiffelthon/multimodal/labled_data'\n",
    "list_unit_folder = ['0001-0400', '0401-0800', '0801-1200', '1201-1600',\\\n",
    "                   '1601-2000', '2001-2400', '2401-2800', '2801-3200', '3201-3600', '3601-4000',\\\n",
    "                   '4001-4400', '4401-4800', '4801-5200', '5201-5600']\n",
    "clip_range = [\n",
    "    (1, 401),\n",
    "    (401, 801),\n",
    "    (801, 1201),\n",
    "    (1201, 1601),\n",
    "    (1601, 2001),\n",
    "    (2001, 2401),\n",
    "    (2401, 2801),\n",
    "    (2801, 3201),\n",
    "    (3201, 3601),\n",
    "    (3601, 4001),\n",
    "    (4001, 4401),\n",
    "    (4401, 4801),\n",
    "    (4801, 5201),\n",
    "    (5201, 5601)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1742bffa-7ff4-42a2-8e06-dce5e829621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_all_json(input_data_root_dir, output_path, list_unit_folder, clip_range)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
