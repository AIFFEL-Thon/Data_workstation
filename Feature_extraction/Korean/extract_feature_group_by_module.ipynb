{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# not used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUnUL7e0RunN"
      },
      "source": [
        "# 0. 환경설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HOBs6BCKA6J",
        "outputId": "0536bbdc-d521-469a-e83f-8e6bcfda5878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: praat-parselmouth in /usr/local/lib/python3.11/dist-packages (0.4.5)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from praat-parselmouth) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install praat-parselmouth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En6X2zxMLGxS",
        "outputId": "3a0a0f24-1b76-42bc-a4d6-e85714ec4138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import parselmouth\n",
        "from parselmouth.praat import call\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import google.colab.drive as drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY6NX3XURsxI"
      },
      "source": [
        "# 1. Extract and Modulate Pitch Contour: Using Threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "Ug3w2KTQ3eu1"
      },
      "outputs": [],
      "source": [
        "# pitch 추출\n",
        "\n",
        "def extract_pitch_values(audio_file):\n",
        "    sound = parselmouth.Sound(audio_file)\n",
        "    pitch = sound.to_pitch_ac(time_step=0.01, pitch_floor=50, pitch_ceiling=500) # time_step=0.01 (default)\n",
        "\n",
        "    # Extract raw pitch values and timestamps\n",
        "    pitch_values = pitch.selected_array['frequency']\n",
        "    time_stamps = pitch.xs()\n",
        "\n",
        "    # Filter out unvoiced segments\n",
        "    valid_indices = pitch_values > 0\n",
        "    pitch_values = pitch_values[valid_indices]\n",
        "    time_stamps = time_stamps[valid_indices]\n",
        "\n",
        "    return pitch_values, time_stamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "OeqZ4WcZtOpm"
      },
      "outputs": [],
      "source": [
        "def get_pitch_over_threshold(audio_file, threshold=10.0):  # threshold=10으로 고정\n",
        "    \"\"\"\n",
        "    Extract stylized pitch features including movement distance and slope from an audio file.\n",
        "    \"\"\"\n",
        "    pitch_values, time_stamps = extract_pitch_values(audio_file)\n",
        "\n",
        "    if len(pitch_values) == 0:  # 값 없으면 빈 리스트 반환 후 호출 종료\n",
        "        print(f\"No valid pitch values found in {audio_file}\")\n",
        "        return []\n",
        "\n",
        "    # Apply manual stylization\n",
        "    applied_pitch = [pitch_values[0]]  # 첫 음높이 값 포함\n",
        "    applied_time = [time_stamps[0]]   # 첫 시간 포함\n",
        "\n",
        "    for i in range(1, len(pitch_values)):\n",
        "        # 이전 값과 현재 값의 차이가 threshold보다 크면 추가\n",
        "        if abs(pitch_values[i] - applied_pitch[-1]) >= threshold:\n",
        "            applied_pitch.append(pitch_values[i])\n",
        "            applied_time.append(time_stamps[i])\n",
        "\n",
        "    applied_pitch, applied_time = np.array(applied_pitch), np.array(applied_time)  # array\n",
        "\n",
        "    # Visualize the results\n",
        "    # visualize_pitch_values(applied_pitch, applied_time, title=\"Stylized Pitch Values\")\n",
        "\n",
        "    # Calculate movement distance and slope\n",
        "    contour_data = [] # 시간, 음높이 저장 리스트\n",
        "    for i in range(1, len(applied_pitch)):\n",
        "        contour_data.append({'time': applied_time[i], 'pitch': applied_pitch[i]}) # dic -> df\n",
        "\n",
        "    return contour_data  # type == list, dic -> df 변환 필요\n",
        "\n",
        "def get_pitch_contour_threshold_process(input_folder, output_file, threshold=10):\n",
        "    \"\"\"\n",
        "    Processes all .wav files in a folder, extracts pitch features, and saves them to a CSV file.\n",
        "    - input_folder: Path to the folder containing .wav files\n",
        "    - output_file: Path to save the output CSV file\n",
        "    - threshold: Threshold for pitch stylization\n",
        "    \"\"\"\n",
        "    f0_contour_values = []  # List to store features from all files\n",
        "\n",
        "    for file_name in os.listdir(input_folder):\n",
        "        if file_name.endswith(\".wav\"):\n",
        "            audio_file = os.path.join(input_folder, file_name)\n",
        "            utterance_contour = get_pitch_over_threshold(audio_file, threshold)\n",
        "\n",
        "            # Convert to DataFrame if it's a list  # error 해결 위해 추가\n",
        "            if isinstance(utterance_contour, list):\n",
        "                utterance_contour = pd.DataFrame(utterance_contour)\n",
        "\n",
        "            if not utterance_contour.empty:\n",
        "                utterance_contour['file_name'] = file_name  # Add file name column\n",
        "                f0_contour_values.append(utterance_contour)  # Append DataFrame\n",
        "\n",
        "    if f0_contour_values:\n",
        "        # Combine all DataFrames into one\n",
        "        combine = pd.concat(f0_contour_values, ignore_index=True)\n",
        "        save_to_csv(combine, output_file)\n",
        "        print(f\"All features saved to {output_file}.\")  # Debugging\n",
        "        return combine\n",
        "    else:\n",
        "        print(\"No pitch data was extracted.\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOCsx2ybR4-8"
      },
      "source": [
        "# 2. Generate Pitch Movement Slope Data\n",
        "- Intonation Curve Standardization\n",
        "- the physical feature of pitch range, moving time, moving distance, slope\n",
        "\n",
        "**Reference**\n",
        "  - Jeahyuk Oh. (2014). *A Study of Methods of Standardization for Korean Intonation Curve*. 한국어학, 62, 395-420.\n",
        "  - Jeahyuk Oh. (2024).*Improving the objectivity of intonation transcription*. 한말연구, 65(25), 1-20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "2XvZHlNts5_G"
      },
      "outputs": [],
      "source": [
        "def calculate_movement_distance_and_slope(pitch_values, time_stamps):\n",
        "    \"\"\"\n",
        "    음높이 움직임의 이동 거리와 기울기를 계산합니다.\n",
        "    \"\"\"\n",
        "    # 음높이 값을 0~100 사이로 정규화합니다.\n",
        "    min_pitch = np.min(pitch_values)  # 음높이의 최솟값\n",
        "    max_pitch = np.max(pitch_values)  # 음높이의 최댓값\n",
        "    normalized_pitch = (pitch_values - min_pitch) / (max_pitch - min_pitch) * 100\n",
        "\n",
        "    # 시간 값을 0~100 사이로 정규화합니다.\n",
        "    min_time = np.min(time_stamps)\n",
        "    max_time = np.max(time_stamps)\n",
        "    normalized_time = (time_stamps - min_time) / (max_time - min_time) * 100\n",
        "\n",
        "    movement_data = []  # 이동 거리와 기울기를 저장할 리스트\n",
        "    for i in range(1, len(normalized_pitch)):\n",
        "        delta_pitch = normalized_pitch[i] - normalized_pitch[i - 1]  # 음높이 차이\n",
        "        delta_time = normalized_time[i] - normalized_time[i - 1]  # 시간 차이\n",
        "        distance = np.sqrt(delta_pitch**2 + delta_time**2)  # 피타고라스 정리로 이동 거리 계산\n",
        "        slope = delta_pitch / delta_time if delta_time != 0 else 0  # 기울기 계산\n",
        "        movement_data.append({\n",
        "            'start_time': normalized_time[i - 1],\n",
        "            'end_time': normalized_time[i],\n",
        "            'start_pitch': normalized_pitch[i - 1],\n",
        "            'end_pitch': normalized_pitch[i],\n",
        "            'distance': distance,\n",
        "            'slope': slope\n",
        "        })\n",
        "\n",
        "    return movement_data\n",
        "\n",
        "def extract_pitch_features_with_stylization_and_distance(audio_file, threshold=10.0):  # threshold 통한 pitch point 조정 과정 포함됨\n",
        "    \"\"\"\n",
        "    Extract stylized pitch features including movement distance and slope from an audio file.\n",
        "    \"\"\"\n",
        "    pitch_values, time_stamps = extract_pitch_values(audio_file)\n",
        "\n",
        "    if len(pitch_values) == 0:\n",
        "        print(f\"No valid pitch values found in {audio_file}\")\n",
        "        return []\n",
        "\n",
        "    # Apply manual stylization\n",
        "    stylized_pitch = [pitch_values[0]]  # 첫 음높이 값 포함\n",
        "    stylized_time = [time_stamps[0]]   # 첫 시간 포함\n",
        "\n",
        "    for i in range(1, len(pitch_values)):\n",
        "        # 이전 값과 현재 값의 차이가 threshold보다 크면 추가\n",
        "        if abs(pitch_values[i] - stylized_pitch[-1]) >= threshold:\n",
        "            stylized_pitch.append(pitch_values[i])\n",
        "            stylized_time.append(time_stamps[i])\n",
        "\n",
        "    stylized_pitch, stylized_time = np.array(stylized_pitch), np.array(stylized_time)\n",
        "\n",
        "    # Visualize the results\n",
        "    # visualize_pitch_values(pitch_values, time_stamps, title=\"Raw Pitch Values\")\n",
        "    # visualize_pitch_values(stylized_pitch, stylized_time, title=\"Stylized Pitch Values\")\n",
        "\n",
        "    # Calculate movement distance and slope\n",
        "    movement_data = calculate_movement_distance_and_slope(stylized_pitch, stylized_time)\n",
        "\n",
        "    return movement_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "hTuC5Ypq_t8K"
      },
      "outputs": [],
      "source": [
        "def get_pitch_movement_process(input_folder, threshold=10, output_csv=\"/content/pitch_movement_data.csv\"):\n",
        "    \"\"\"\n",
        "    Processes all .wav files in a folder, extracts pitch features, and saves them to a CSV file.\n",
        "    - threshold: Threshold for pitch stylization\n",
        "    - output_csv: Output file name for the processed data\n",
        "    \"\"\"\n",
        "    pitch_movement_data = []\n",
        "\n",
        "    for file_name in os.listdir(input_folder):\n",
        "        if file_name.endswith(\".wav\"):  # Process only .wav files\n",
        "            audio_file = os.path.join(input_folder, file_name)\n",
        "            try:\n",
        "                utterance_movement = extract_pitch_features_with_stylization_and_distance(audio_file, threshold)\n",
        "\n",
        "                if not utterance_movement:\n",
        "                    print(f\"No pitch data for {file_name}, skipping.\")\n",
        "                    continue\n",
        "\n",
        "                # Add a column to identify the source file\n",
        "                for entry in utterance_movement:\n",
        "                    entry['file_name'] = file_name\n",
        "\n",
        "                pitch_movement_data.extend(utterance_movement)\n",
        "\n",
        "                print(f\"Processed {file_name}.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_name}: {e}\")\n",
        "\n",
        "    # Convert the list of dictionaries to a DataFrame\n",
        "    df_movement = pd.DataFrame(pitch_movement_data)\n",
        "\n",
        "    # Save to CSV\n",
        "    if not df_movement.empty:\n",
        "        df_movement.to_csv(output_csv, index=False)\n",
        "        print(f\"Saved pitch movement data to {output_csv}\")\n",
        "        return df_movement\n",
        "    else:\n",
        "        print(\"No valid data to save.\")\n",
        "        return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "vk60L4-YV5dB"
      },
      "outputs": [],
      "source": [
        "def merge_pitch_movement_data(df, full_data):\n",
        "    df_pitch_movement = df.copy()\n",
        "\n",
        "    # 불러온 데이터에서 필요한 행만 필터링\n",
        "    matching_filenames = df_pitch_movement['file_name'].unique()\n",
        "    filtered_data = full_data[full_data['voice_piece_filename'].isin(matching_filenames)]\n",
        "\n",
        "    # 필요한 컬럼만 유지\n",
        "    columns_to_keep = ['voice_piece_filename', 'styles', 'emotions', 'gender', 'age', 'disagree']\n",
        "    filtered_data = filtered_data[columns_to_keep]\n",
        "\n",
        "    # 원본 데이터프레임과 필터링된 데이터프레임 결합\n",
        "    merged_data = df_pitch_movement.merge(filtered_data, left_on='file_name', right_on='voice_piece_filename', how='inner')\n",
        "\n",
        "    return merged_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "h1INhcxeo54u"
      },
      "outputs": [],
      "source": [
        "def group_pitch_data(df):\n",
        "    \"\"\"\n",
        "    Groups pitch data by 'file_name'.\n",
        "    - df: DataFrame containing pitch features\n",
        "    - Returns: Grouped object\n",
        "    \"\"\"\n",
        "    if not df.empty:\n",
        "        return df.groupby('file_name')\n",
        "    else:\n",
        "        print(\"DataFrame is empty. Cannot group data.\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NZmCZo6WfY4"
      },
      "source": [
        "# 3. Intonation Curve Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "f-L5tdlxWgkS"
      },
      "outputs": [],
      "source": [
        "def stylize_pitch_tier_from_sound(audio_file, frequency_resolution=2.0, pitch_floor=50, pitch_ceiling=500):\n",
        "    \"\"\"\n",
        "    음성 파일에서 PitchTier를 생성하고 유형화 합니다.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        sound = parselmouth.Sound(audio_file)\n",
        "\n",
        "        # PitchTier로 변환\n",
        "        manipulation = call(sound, \"To Manipulation\", 0.01, pitch_floor, pitch_ceiling)\n",
        "        pitch_tier = call(manipulation, \"Extract pitch tier\")\n",
        "\n",
        "        # 근접 복사 유형화 수행\n",
        "        call(pitch_tier, \"Stylize...\", frequency_resolution, \"semitones\")\n",
        "\n",
        "        # 결과값 추출\n",
        "        # PitchTire 객체에서는 값 추출이 불가능함 (API 제공 X). Praat의 Synthesize > \"To Pitch...\" 이용하여 다시 pitch 객체로 변환\n",
        "        close_copy_pitch = call(pitch_tier, \"To Pitch...\", 0.01, pitch_floor, pitch_ceiling)\n",
        "        stylized_pitch = close_copy_pitch.selected_array['frequency']\n",
        "        stylized_time = close_copy_pitch.xs()\n",
        "\n",
        "        if len(stylized_time) == 0 or len(stylized_pitch) == 0:\n",
        "            raise ValueError(\"Stylized time or pitch is empty.\")\n",
        "\n",
        "        return np.array(stylized_time), np.array(stylized_pitch)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {audio_file}: {e}\")\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "def calculate_slopes(stylized_time, stylized_pitch):\n",
        "    \"\"\"\n",
        "    유형화 된 Pitch 데이터를 바탕으로 각 구간의 기울기를 계산합니다.\n",
        "    \"\"\"\n",
        "    slopes = []\n",
        "    for i in range(1, len(stylized_time)):\n",
        "        delta_pitch = stylized_pitch[i] - stylized_pitch[i - 1]\n",
        "        delta_time = stylized_time[i] - stylized_time[i - 1]\n",
        "        slope = delta_pitch / delta_time if delta_time != 0 else 0\n",
        "        slopes.append(slope)\n",
        "    return np.array(slopes)\n",
        "\n",
        "\n",
        "def plot_pitch_stylization(time_stamps, pitch_values, stylized_time, stylized_pitch, output_path=None):\n",
        "    \"\"\"\n",
        "    음높이 곡선과 근접 복사 유형화 결과를 시각화합니다.\n",
        "    - time_stamps: 원래의 시간 값 배열\n",
        "    - pitch_values: 원래의 음높이 값 배열\n",
        "    - stylized_time: 스타일화된 시간 값 배열\n",
        "    - stylized_pitch: 스타일화된 음높이 값 배열\n",
        "    - output_path: 그래프 저장 경로 (None이면 저장하지 않음)\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 원 음높이 곡선\n",
        "    plt.plot(time_stamps, pitch_values, label=\"Original Pitch Contour\", color=\"gray\", linestyle=\"--\")\n",
        "\n",
        "    # 스타일화된 음높이 곡선\n",
        "    plt.plot(stylized_time, stylized_pitch, label=\"Stylized Pitch Contour\", color=\"green\", marker=\"o\", linewidth=2)\n",
        "\n",
        "    # 그래프 설정\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Pitch (Hz)\")\n",
        "    plt.title(\"Close-Copy Stylization\")\n",
        "    plt.ylim(50, 500) # 음역대와 일치\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # 그래프 저장 또는 표시\n",
        "    if output_path:\n",
        "        plt.savefig(output_path)\n",
        "        print(f\"Plot saved to {output_path}\")\n",
        "    plt.show()\n",
        "\n",
        "def save_stylized_pitch(stylized_time, stylized_pitch, slopes, output_file):\n",
        "    \"\"\"\n",
        "    유형화 된 음높이 데이터를 CSV 파일로 저장합니다.\n",
        "    \"\"\"\n",
        "    # slopes의 길이를 stylized_time과 맞추기 위해 None 값을 추가\n",
        "    if len(slopes) < len(stylized_time):\n",
        "        slopes = list(slopes) + [None]  # 마지막 구간의 기울기 값 없음 처리\n",
        "\n",
        "    data = {\n",
        "        \"Time (s)\": stylized_time,\n",
        "        \"Pitch (Hz)\": stylized_pitch,\n",
        "        \"Slope\": slopes\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Stylized pitch data saved to {output_file}\")\n",
        "\n",
        "def get_pitch_stylized_data(input_folder, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for file_name in os.listdir(input_folder):\n",
        "        if file_name.endswith(\".wav\"):\n",
        "            sound_file = os.path.join(input_folder, file_name)\n",
        "\n",
        "            base_name = os.path.splitext(file_name)[0]\n",
        "            output_plot = os.path.join(output_folder, f\"{base_name}_plot.png\")\n",
        "            output_csv = os.path.join(output_folder, f\"{base_name}_pitch.csv\")\n",
        "\n",
        "            try:\n",
        "                # PitchTier 유형화 수행\n",
        "                stylized_time, stylized_pitch = stylize_pitch_tier_from_sound(sound_file, frequency_resolution=2.0)\n",
        "\n",
        "                # 각 구간의 기울기 계산\n",
        "                slopes = calculate_slopes(stylized_time, stylized_pitch)\n",
        "\n",
        "                # 시각화\n",
        "                plot_pitch_stylization(stylized_time, stylized_pitch, stylized_time, stylized_pitch, output_path=output_plot)\n",
        "\n",
        "                # 결과 저장\n",
        "                save_stylized_pitch(stylized_time, stylized_pitch, slopes, output_csv)\n",
        "\n",
        "                print(f\"Processed {file_name}: Plot saved to {output_plot}, CSV saved to {output_csv}.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to process {file_name}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaNv2WmPzqdO"
      },
      "source": [
        "# **Baseline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "jy8ytj9oNNG7"
      },
      "outputs": [],
      "source": [
        "# data\n",
        "input_folder = \"/content/drive/MyDrive/AIFFELthon/Data/Sample/literature_100/sample\" # Speech corpus (Raw data)\n",
        "drive_csv_path = \"/content/drive/MyDrive/AIFFELthon/Data/Literature/label_lit.csv\" # Labeling data\n",
        "full_data = pd.read_csv(drive_csv_path)\n",
        "\n",
        "output_contour = \"/content/pitch_contour_data.csv\"\n",
        "output_movement = \"/content/pitch_movement_data.csv\"\n",
        "output_stylization_folder = \"/content/processed_results_res2.0\"  # 근접복사유형화 결과 파일을 저장할 폴더"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "yjpM20H9PFyc"
      },
      "outputs": [],
      "source": [
        "def entry_point() :\n",
        "    # Data 1: threshold\n",
        "    df_pitch_countour = get_pitch_contour_threshold_process(input_folder, output_contour, threshold=10) \n",
        "\n",
        "    # Data 2: pitch movement slope \n",
        "    df_pitch_movement = get_pitch_movement_process(input_folder, threshold=10, output_csv=output_movement)\n",
        "\n",
        "    # Data 3: Stylized data\n",
        "    get_pitch_stylized_data(input_folder, output_stylization_folder) \n",
        "\n",
        "    return df_pitch_countour, df_pitch_movement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmsjYFCo99__",
        "outputId": "982f9c0f-f070-4b86-c89a-ba2b84217b25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed S0171-09-11-05.wav.\n",
            "Processed S0171-09-11-08.wav.\n",
            "Processed S0171-09-11-07.wav.\n",
            "Processed S0171-09-11-10.wav.\n",
            "Processed S0171-09-11-09.wav.\n",
            "Processed S0171-09-11-04.wav.\n",
            "Processed S0171-09-11-03.wav.\n",
            "Processed S0171-09-11-01.wav.\n",
            "Processed S0171-09-11-06.wav.\n",
            "Processed S0171-09-11-02.wav.\n",
            "Processed S0171-09-11-00.wav.\n",
            "Processed S0171-10-14-03.wav.\n",
            "Processed S0171-10-14-06.wav.\n",
            "Processed S0171-10-14-00.wav.\n",
            "Processed S0171-10-14-02.wav.\n",
            "Processed S0171-10-14-08.wav.\n",
            "Processed S0171-10-14-07.wav.\n",
            "Processed S0171-10-14-01.wav.\n",
            "Processed S0171-10-14-04.wav.\n",
            "Processed S0171-10-14-09.wav.\n",
            "Processed S0171-10-14-05.wav.\n",
            "Processed S0171-10-06-01.wav.\n",
            "Processed S0171-10-06-03.wav.\n",
            "Processed S0171-10-06-00.wav.\n",
            "Processed S0171-10-06-05.wav.\n",
            "Processed S0171-10-06-02.wav.\n",
            "Processed S0171-10-06-04.wav.\n",
            "Processed S0171-10-06-06.wav.\n",
            "Processed S0171-10-06-08.wav.\n",
            "No valid pitch values found in /content/drive/MyDrive/AIFFELthon/Data/Sample/literature_100/sample/S0171-10-06-09.wav\n",
            "No pitch data for S0171-10-06-09.wav, skipping.\n",
            "Processed S0171-10-06-07.wav.\n",
            "Processed S0171-10-01-06.wav.\n",
            "Processed S0171-10-01-03.wav.\n",
            "Processed S0171-10-01-00.wav.\n",
            "Processed S0171-10-01-09.wav.\n",
            "Processed S0171-10-01-08.wav.\n",
            "Processed S0171-10-01-01.wav.\n",
            "Processed S0171-10-01-07.wav.\n",
            "Processed S0171-10-01-02.wav.\n",
            "Processed S0171-10-01-05.wav.\n",
            "Processed S0171-10-01-04.wav.\n",
            "Processed S0171-09-07-05.wav.\n",
            "Processed S0171-09-07-10.wav.\n",
            "Processed S0171-09-07-04.wav.\n",
            "Processed S0171-09-07-09.wav.\n",
            "Processed S0171-09-07-07.wav.\n",
            "Processed S0171-09-07-08.wav.\n",
            "Processed S0171-09-07-06.wav.\n",
            "Processed S0171-09-16-03.wav.\n",
            "Processed S0171-09-16-06.wav.\n",
            "Processed S0171-09-16-00.wav.\n",
            "Processed S0171-09-16-09.wav.\n",
            "Processed S0171-09-16-02.wav.\n",
            "Processed S0171-09-16-08.wav.\n",
            "Processed S0171-09-16-05.wav.\n",
            "Processed S0171-09-16-04.wav.\n",
            "Processed S0171-09-16-07.wav.\n",
            "Processed S0171-09-16-01.wav.\n",
            "Processed S0171-09-16-10.wav.\n",
            "Processed S0171-10-17-03.wav.\n",
            "Processed S0171-10-17-08.wav.\n",
            "Processed S0171-10-17-00.wav.\n",
            "Processed S0171-10-17-07.wav.\n",
            "Processed S0171-10-17-06.wav.\n",
            "Processed S0171-10-17-05.wav.\n",
            "Processed S0171-10-17-01.wav.\n",
            "Processed S0171-10-17-04.wav.\n",
            "Processed S0171-10-17-02.wav.\n",
            "Processed S0171-10-17-09.wav.\n",
            "Processed S0171-10-08-09.wav.\n",
            "Processed S0171-10-08-05.wav.\n",
            "Processed S0171-10-08-08.wav.\n",
            "Processed S0171-10-08-07.wav.\n",
            "Processed S0171-10-08-04.wav.\n",
            "Processed S0171-10-08-03.wav.\n",
            "Processed S0171-10-08-00.wav.\n",
            "Processed S0171-10-08-06.wav.\n",
            "Processed S0171-10-08-02.wav.\n",
            "Processed S0171-10-08-01.wav.\n",
            "Processed S0171-09-13-02.wav.\n",
            "Processed S0171-09-13-08.wav.\n",
            "Processed S0171-09-13-10.wav.\n",
            "Processed S0171-09-13-01.wav.\n",
            "Processed S0171-09-13-04.wav.\n",
            "Processed S0171-09-13-09.wav.\n",
            "Processed S0171-09-13-05.wav.\n",
            "Processed S0171-09-13-00.wav.\n",
            "Processed S0171-09-13-07.wav.\n",
            "Processed S0171-09-13-06.wav.\n",
            "Processed S0171-09-13-03.wav.\n",
            "Processed S0171-10-02-07.wav.\n",
            "Processed S0171-10-02-05.wav.\n",
            "Processed S0171-10-02-00.wav.\n",
            "Processed S0171-10-02-08.wav.\n",
            "Processed S0171-10-02-03.wav.\n",
            "Processed S0171-10-02-09.wav.\n",
            "Processed S0171-10-02-02.wav.\n",
            "Processed S0171-10-02-01.wav.\n",
            "Processed S0171-10-02-04.wav.\n",
            "Processed S0171-10-02-06.wav.\n",
            "Saved pitch movement data to /content/pitch_movement_data.csv\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    entry_point()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "eUnUL7e0RunN"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
