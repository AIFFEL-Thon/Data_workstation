{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FMdVNN9227F0"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Extract Boundary Tone Feature from Korean Speech Dataset\n",
        "- Intonation Annotation through pitch slope in *Intonation Phrase (IP)*"
      ],
      "metadata": {
        "id": "bzvs8FdL3eg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 파일 구조:\n",
        "\n",
        "  input_audio_dir: 원본 .wav 파일이 저장된 디렉터리.\n",
        "\n",
        "  input_json_dir: JSON 라벨 파일이 저장된 디렉터리.\n",
        "  \n",
        "  output_audio_dir: 분리된 발화 .wav 파일을 저장할 디렉터리.\n",
        "  \n",
        "  output_csv_path: 최종 결과를 저장할 CSV 파일 경로.\n",
        "- JSON에서 발화 정보 추출:\n",
        "\n",
        "  발화의 시작 시간 (StartTime)과 종료 시간 (EndTime)을 기준으로 원본 오디오 파일에서 발화를 분리.\n",
        "- Pitch 기울기와 억양 주석 계산:\n",
        "\n",
        "  librosa를 사용해 pitch 데이터를 추출하고, 기울기 및 억양 주석 정보를 생성.\n",
        "- 결과 저장:\n",
        "\n",
        "  분리된 발화 오디오 파일 이름, 감정 레이블 (emotion), pitch 기울기, 억양 주석 정보를 포함한 결과를 DataFrame으로 정리하고 CSV로 저장.\n",
        "- 결과 CSV 파일 컬럼:\n",
        "\n",
        "  ID: 발화별로 생성된 새로운 .wav 파일 이름.\n",
        "  \n",
        "  emotion: JSON에서 추출한 감정 레이블.\n",
        "  \n",
        "  pitch_slope: 발화별 pitch 기울기 데이터 (리스트).\n",
        "  \n",
        "  intonation_annotation: 발화별 억양 주석 데이터 (리스트)."
      ],
      "metadata": {
        "id": "94bk4e7Dz1g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praat-parselmouth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8yHTHRL2jJZ",
        "outputId": "6dfaffe7-0d4e-4dcb-8466-bc16c418c64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praat-parselmouth\n",
            "  Downloading praat_parselmouth-0.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from praat-parselmouth) (1.26.4)\n",
            "Downloading praat_parselmouth-0.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (10.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: praat-parselmouth\n",
            "Successfully installed praat-parselmouth-0.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "import json\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.interpolate import interp1d\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import parselmouth\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Ve5Tvi3c2YSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 압축 파일 경로\n",
        "zip_file_audio = \"/content/train.zip\"  # 첫 번째 압축 파일 경로\n",
        "zip_file_labeling = \"/content/train_labeling.zip\"  # 두 번째 압축 파일 경로"
      ],
      "metadata": {
        "id": "bMz42wU2gyAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일이 올바른 zip 파일인지 확인하는 함수\n",
        "def check_zip_file(file_path):\n",
        "    try:\n",
        "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "            # zip 파일 내용 확인\n",
        "            zip_ref.testzip()\n",
        "        return True\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: {file_path} is not a valid zip file.\")\n",
        "        return False\n",
        "\n",
        "# 압축 해제할 경로 설정\n",
        "extract_audio_dir = \"/content/extracted_audio_files\"  # 오디오 파일 압축 해제 경로\n",
        "extract_labeling_dir = \"/content/extracted_labeling_files\"  # 라벨링 파일 압축 해제 경로\n",
        "\n",
        "# 파일 경로 체크 후 압축 해제\n",
        "if check_zip_file(zip_file_audio):\n",
        "    os.makedirs(extract_audio_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_file_audio, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_audio_dir)  # 오디오 파일 압축 해제\n",
        "\n",
        "if check_zip_file(zip_file_labeling):\n",
        "    os.makedirs(extract_labeling_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_file_labeling, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_labeling_dir)  # 라벨링 파일 압축 해제\n",
        "\n",
        "# 경로 설정\n",
        "input_audio_dir = extract_audio_dir  # 원본 .wav 파일이 포함된 폴더 경로\n",
        "input_json_dir = extract_labeling_dir  # JSON 파일이 포함된 폴더 경로\n",
        "output_audio_dir = \"/content/output_wavs\"  # 발화별 .wav 파일 저장 경로\n",
        "os.makedirs(output_audio_dir, exist_ok=True)\n",
        "\n",
        "output_csv_path = \"/content/utterance_features.csv\"  # 최종 .csv 파일 경로\n",
        "\n",
        "# 경로 확인\n",
        "print(\"원본 오디오 파일 경로:\", input_audio_dir)\n",
        "print(\"라벨링 JSON 파일 경로:\", input_json_dir)\n",
        "print(\"발화별 오디오 저장 경로:\", output_audio_dir)\n",
        "print(\"최종 CSV 파일 경로:\", output_csv_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go5ytAvrGdZl",
        "outputId": "f0f17705-6f6b-45b3-d594-34ab1380f320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 오디오 파일 경로: /content/extracted_audio_files\n",
            "라벨링 JSON 파일 경로: /content/extracted_labeling_files\n",
            "발화별 오디오 저장 경로: /content/output_wavs\n",
            "최종 CSV 파일 경로: /content/utterance_features.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.interpolate import interp1d\n",
        "import parselmouth\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 피치 기울기 및 억양 주석 함수\n",
        "def calculate_pitch_slope(pitch_times, pitch_values, start_time, end_time):\n",
        "    within_range = (pitch_times >= start_time) & (pitch_times <= end_time)\n",
        "    segment_times = pitch_times[within_range]\n",
        "    segment_values = pitch_values[within_range]\n",
        "\n",
        "    if len(segment_times) < 2 or np.isnan(segment_values).all():\n",
        "        return None, None, \"Insufficient data\"\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(segment_times.reshape(-1, 1), segment_values)\n",
        "    slope = model.coef_[0]\n",
        "    return slope, segment_values, model, \"Slope calculated\"\n",
        "\n",
        "def annotate_intonation(slope, segment_values, full_pitch_values, rise_threshold=0.5, flat_threshold=0.1):\n",
        "    if slope is None:\n",
        "        return \"No annotation (insufficient data)\"\n",
        "    if slope > rise_threshold:\n",
        "        return \"H%\"\n",
        "    elif slope < -rise_threshold:\n",
        "        return \"L%\"\n",
        "    elif abs(slope) <= flat_threshold:\n",
        "        full_mean_pitch = np.nanmean(full_pitch_values)\n",
        "        segment_mean_pitch = np.nanmean(segment_values)\n",
        "        return \"H%\" if segment_mean_pitch > full_mean_pitch else \"L%\"\n",
        "    else:\n",
        "        return \"Flat\"\n",
        "\n",
        "def process_and_annotate_pitch(\n",
        "    sound_path,\n",
        "    last_phrase_start=1.943,  # Hardcoded start time for last phrase\n",
        "    time_step=0.01,\n",
        "    pitch_floor=100,\n",
        "    pitch_ceiling=450,\n",
        "    rise_threshold=0.5,\n",
        "    flat_threshold=0.1\n",
        "):\n",
        "    \"\"\"\n",
        "    Process the sound file, calculate pitch slope, and annotate intonation.\n",
        "    \"\"\"\n",
        "    sound = parselmouth.Sound(sound_path)\n",
        "    pitch = sound.to_pitch(time_step=time_step, pitch_floor=pitch_floor, pitch_ceiling=pitch_ceiling)\n",
        "    pitch_values = pitch.selected_array['frequency']\n",
        "    pitch_times = pitch.xs()\n",
        "    pitch_values[pitch_values == 0] = np.nan\n",
        "\n",
        "    # 유효한 값만 필터링\n",
        "    valid_idx = ~np.isnan(pitch_values)\n",
        "\n",
        "    # 유효한 값이 하나도 없는 경우 처리\n",
        "    if valid_idx.sum() == 0:\n",
        "        print(f\"No valid pitch data for {sound_path} between {last_phrase_start} and {pitch_times[-1]}.\")\n",
        "        return None, \"No valid pitch data\"\n",
        "\n",
        "    # 보간 함수 정의\n",
        "    interp_function = interp1d(\n",
        "        pitch_times[valid_idx],\n",
        "        pitch_values[valid_idx],\n",
        "        kind=\"linear\",\n",
        "        bounds_error=False,\n",
        "        fill_value=np.nan\n",
        "    )\n",
        "\n",
        "    # 보간된 피치 값 생성\n",
        "    interpolated_pitch = interp_function(pitch_times)\n",
        "\n",
        "    # 기울기 계산\n",
        "    slope, segment_values, model, status = calculate_pitch_slope(pitch_times, interpolated_pitch, last_phrase_start, pitch_times[-1])\n",
        "\n",
        "    if slope is None:\n",
        "        annotation = \"No annotation (insufficient data)\"\n",
        "    else:\n",
        "        annotation = annotate_intonation(slope, segment_values, interpolated_pitch)\n",
        "\n",
        "    return slope, annotation\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nV8rQ-EhHeZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 발화 단위로 .wav 파일 분리 및 정보 추출\n",
        "results = []\n",
        "\n",
        "for json_file in os.listdir(input_json_dir):\n",
        "    if not json_file.endswith(\".json\"):\n",
        "        continue\n",
        "\n",
        "    with open(os.path.join(input_json_dir, json_file), \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    audio_file_name = data[\"File\"][\"FileName\"] + \".wav\"\n",
        "    audio_file_path = os.path.join(output_audio_dir, audio_file_name)\n",
        "\n",
        "    if not os.path.exists(audio_file_path):\n",
        "        print(f\"Audio file not found: {audio_file_path}\")\n",
        "        continue\n",
        "\n",
        "    y, sr = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "    for utterance in data[\"Conversation\"]:\n",
        "        try:\n",
        "            start_time = float(utterance[\"StartTime\"].replace(\",\", \"\"))\n",
        "            end_time = float(utterance[\"EndTime\"].replace(\",\", \"\"))\n",
        "        except ValueError as e:\n",
        "            print(f\"Error converting times for {utterance['TextNo']}: {e}\")\n",
        "            continue  # 시간 변환에 실패하면 해당 발화를 건너뜁니다.\n",
        "\n",
        "        emotion = utterance[\"SpeakerEmotionTarget\"]\n",
        "        utterance_id = utterance[\"TextNo\"]\n",
        "\n",
        "        start_sample = int(start_time * sr)\n",
        "        end_sample = int(end_time * sr)\n",
        "        y_segment = y[start_sample:end_sample]\n",
        "\n",
        "        segment_file_name = f\"{data['File']['FileName']}_{utterance_id}.wav\"\n",
        "        segment_file_path = os.path.join(output_audio_dir, segment_file_name)\n",
        "        sf.write(segment_file_path, y_segment, sr)\n",
        "\n",
        "        slope, annotation = process_and_annotate_pitch(segment_file_path, last_phrase_start=start_time)\n",
        "        results.append({\n",
        "            \"ID\": segment_file_name,\n",
        "            \"emotion\": emotion,\n",
        "            \"pitch_slope\": slope,\n",
        "            \"intonation_annotation\": annotation\n",
        "        })\n",
        "\n",
        "\n",
        "# 결과를 DataFrame으로 저장 및 CSV로 내보내기\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"처리가 완료되었습니다. 결과는 {output_csv_path}에 저장되었습니다.\")"
      ],
      "metadata": {
        "id": "WYraC4hwfXC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 마지막 음절 구간 추출 후 억양 주석 달도록 수정"
      ],
      "metadata": {
        "id": "mdarB-wkd7pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import parselmouth\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "def get_last_syllable_times(sound_path, time_step=0.01, pitch_floor=75, pitch_ceiling=500):\n",
        "    \"\"\"\n",
        "    주어진 음성 파일에서 마지막 음절의 시작 시간과 끝 시간을 추출.\n",
        "    \"\"\"\n",
        "    # Praat의 Sound 객체 생성\n",
        "    sound = parselmouth.Sound(sound_path)\n",
        "\n",
        "    # 피치 분석\n",
        "    pitch = sound.to_pitch(time_step=time_step, pitch_floor=pitch_floor, pitch_ceiling=pitch_ceiling)\n",
        "    pitch_values = pitch.selected_array['frequency']\n",
        "    pitch_times = pitch.xs()\n",
        "\n",
        "    # 유효한 피치 값만 필터링\n",
        "    valid_idx = ~np.isnan(pitch_values)\n",
        "    valid_times = pitch_times[valid_idx]\n",
        "\n",
        "    if len(valid_times) == 0:\n",
        "        print(f\"유효한 피치 값이 없습니다: {sound_path}\")\n",
        "        return None, None\n",
        "\n",
        "    # 마지막 피치 구간 찾기\n",
        "    last_pitch_time = valid_times[-1]\n",
        "\n",
        "    # 마지막 음절의 시작 시간 추정\n",
        "    start_time = last_pitch_time - (time_step * 2)  # 대략적인 범위 설정\n",
        "    start_time = max(0, start_time)  # 0 이하 방지\n",
        "\n",
        "    return start_time, last_pitch_time\n",
        "\n",
        "def calculate_pitch_slope(pitch_times, pitch_values, start_time, end_time):\n",
        "    \"\"\"\n",
        "    피치 구간의 기울기를 계산.\n",
        "    \"\"\"\n",
        "    within_range = (pitch_times >= start_time) & (pitch_times <= end_time)\n",
        "    segment_times = pitch_times[within_range]\n",
        "    segment_values = pitch_values[within_range]\n",
        "\n",
        "    if len(segment_times) < 2 or np.isnan(segment_values).all():\n",
        "        return None, None, \"Insufficient data\"\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(segment_times.reshape(-1, 1), segment_values)\n",
        "    slope = model.coef_[0]\n",
        "    return slope, segment_values, model, \"Slope calculated\"\n",
        "\n",
        "def annotate_intonation(slope, segment_values, full_pitch_values, rise_threshold=0.5, flat_threshold=0.1):\n",
        "    \"\"\"\n",
        "    피치 기울기를 기반으로 억양 주석을 생성.\n",
        "    \"\"\"\n",
        "    if slope is None:\n",
        "        return \"No annotation (insufficient data)\"\n",
        "    if slope > rise_threshold:\n",
        "        return \"H%\"\n",
        "    elif slope < -rise_threshold:\n",
        "        return \"L%\"\n",
        "    elif abs(slope) <= flat_threshold:\n",
        "        full_mean_pitch = np.nanmean(full_pitch_values)\n",
        "        segment_mean_pitch = np.nanmean(segment_values)\n",
        "        return \"H%\" if segment_mean_pitch > full_mean_pitch else \"L%\"\n",
        "    else:\n",
        "        return \"Flat\"\n",
        "\n",
        "def process_and_annotate_pitch(\n",
        "    sound_path,\n",
        "    last_phrase_start,\n",
        "    time_step=0.01,\n",
        "    pitch_floor=100,\n",
        "    pitch_ceiling=450,\n",
        "    rise_threshold=0.5,\n",
        "    flat_threshold=0.1\n",
        "):\n",
        "    \"\"\"\n",
        "    억양 주석을 생성하는 함수.\n",
        "    \"\"\"\n",
        "    sound = parselmouth.Sound(sound_path)\n",
        "    pitch = sound.to_pitch(time_step=time_step, pitch_floor=pitch_floor, pitch_ceiling=pitch_ceiling)\n",
        "    pitch_values = pitch.selected_array['frequency']\n",
        "    pitch_times = pitch.xs()\n",
        "    pitch_values[pitch_values == 0] = np.nan\n",
        "\n",
        "    valid_idx = ~np.isnan(pitch_values)\n",
        "\n",
        "    if valid_idx.sum() == 0:\n",
        "        print(f\"No valid pitch data for {sound_path}.\")\n",
        "        return None, \"No valid pitch data\"\n",
        "\n",
        "    interp_function = interp1d(\n",
        "        pitch_times[valid_idx],\n",
        "        pitch_values[valid_idx],\n",
        "        kind=\"linear\",\n",
        "        bounds_error=False,\n",
        "        fill_value=np.nan\n",
        "    )\n",
        "\n",
        "    interpolated_pitch = interp_function(pitch_times)\n",
        "\n",
        "    end_time = pitch_times[-1]  # 마지막 피치 시간\n",
        "    slope, segment_values, status = calculate_pitch_slope(pitch_times, interpolated_pitch, last_phrase_start, end_time)\n",
        "\n",
        "    if slope is None:\n",
        "        annotation = \"No annotation (insufficient data)\"\n",
        "    else:\n",
        "        annotation = annotate_intonation(slope, segment_values, interpolated_pitch, rise_threshold, flat_threshold)\n",
        "\n",
        "    return slope, annotation\n",
        "\n",
        "# 전체 프로세스 수행\n",
        "input_audio_dir = \"/path/to/audio_files\"\n",
        "output_json_path = \"/path/to/output.json\"\n",
        "\n",
        "results = []\n",
        "for audio_file in os.listdir(input_audio_dir):\n",
        "    if not audio_file.endswith(\".wav\"):\n",
        "        continue\n",
        "\n",
        "    audio_path = os.path.join(input_audio_dir, audio_file)\n",
        "\n",
        "    # 마지막 음절 구간 추출\n",
        "    start_time, end_time = get_last_syllable_times(audio_path)\n",
        "\n",
        "    if start_time is None or end_time is None:\n",
        "        print(f\"Skipping {audio_file} due to insufficient data.\")\n",
        "        continue\n",
        "\n",
        "    # 억양 주석 처리\n",
        "    slope, annotation = process_and_annotate_pitch(audio_path, last_phrase_start=start_time)\n",
        "    results.append({\n",
        "        \"audio_file\": audio_file,\n",
        "        \"last_syllable_start_time\": start_time,\n",
        "        \"last_syllable_end_time\": end_time,\n",
        "        \"pitch_slope\": slope,\n",
        "        \"intonation_annotation\": annotation\n",
        "    })\n",
        "\n",
        "# 결과 저장\n",
        "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"처리가 완료되었습니다. 결과는 {output_json_path}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "m6RzzquTd7Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 발화 단위로 .wav 파일 분리 및 정보 추출\n",
        "results = []\n",
        "\n",
        "for json_file in os.listdir(input_json_dir):\n",
        "    if not json_file.endswith(\".json\"):\n",
        "        continue\n",
        "\n",
        "    with open(os.path.join(input_json_dir, json_file), \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    audio_file_name = data[\"File\"][\"FileName\"] + \".wav\"\n",
        "    audio_file_path = os.path.join(output_audio_dir, audio_file_name)\n",
        "\n",
        "    if not os.path.exists(audio_file_path):\n",
        "        print(f\"Audio file not found: {audio_file_path}\")\n",
        "        continue\n",
        "\n",
        "    y, sr = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "    for utterance in data[\"Conversation\"]:\n",
        "        try:\n",
        "            start_time = float(utterance[\"StartTime\"].replace(\",\", \"\"))\n",
        "            end_time = float(utterance[\"EndTime\"].replace(\",\", \"\"))\n",
        "        except ValueError as e:\n",
        "            print(f\"Error converting times for {utterance['TextNo']}: {e}\")\n",
        "            continue  # 시간 변환에 실패하면 해당 발화를 건너뜁니다.\n",
        "\n",
        "        emotion = utterance[\"SpeakerEmotionTarget\"]\n",
        "        utterance_id = utterance[\"TextNo\"]\n",
        "\n",
        "        start_sample = int(start_time * sr)\n",
        "        end_sample = int(end_time * sr)\n",
        "        y_segment = y[start_sample:end_sample]\n",
        "\n",
        "        segment_file_name = f\"{data['File']['FileName']}_{utterance_id}.wav\"\n",
        "        segment_file_path = os.path.join(output_audio_dir, segment_file_name)\n",
        "        sf.write(segment_file_path, y_segment, sr)\n",
        "\n",
        "        slope, annotation = process_and_annotate_pitch(segment_file_path, last_phrase_start=start_time)\n",
        "        results.append({\n",
        "            \"ID\": segment_file_name,\n",
        "            \"emotion\": emotion,\n",
        "            \"pitch_slope\": slope,\n",
        "            \"intonation_annotation\": annotation\n",
        "        })\n",
        "\n",
        "\n",
        "# 결과를 DataFrame으로 저장 및 CSV로 내보내기\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"처리가 완료되었습니다. 결과는 {output_csv_path}에 저장되었습니다.\")"
      ],
      "metadata": {
        "id": "VM-avagFnTJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 수정"
      ],
      "metadata": {
        "id": "QuQ4uXaVowYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import parselmouth\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "# praat -> librosa 변경\n",
        "import librosa\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "javGjviwwfgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 에러\n",
        "\n",
        "- 마지막 음절 구간을 정확히 추출할 수 없어, 피치 데이터를 사용하려고 하면 에러가 남\n",
        "- 우선 시간이 아닌, 유효한 피치 중 마지막 추출 범위를 인식하도록 하겠음"
      ],
      "metadata": {
        "id": "skojnV_PzNPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# def get_last_syllable_times(sound_path, time_step=0.01, pitch_floor=75, pitch_ceiling=500):\n",
        "#     \"\"\"\n",
        "#     주어진 음성 파일에서 마지막 음절의 시작 시간과 끝 시간을 추출.\n",
        "#     \"\"\"\n",
        "#     sound = parselmouth.Sound(sound_path)\n",
        "#     pitch = sound.to_pitch(time_step=time_step, pitch_floor=pitch_floor, pitch_ceiling=pitch_ceiling)\n",
        "#     pitch_values = pitch.selected_array['frequency']\n",
        "#     pitch_times = pitch.xs()\n",
        "\n",
        "#     valid_idx = ~np.isnan(pitch_values)\n",
        "#     valid_times = pitch_times[valid_idx]\n",
        "\n",
        "#     if len(valid_times) == 0:\n",
        "#         print(f\"유효한 피치 값이 없습니다: {sound_path}\")\n",
        "#         return None, None\n",
        "\n",
        "#     last_pitch_time = valid_times[-1]\n",
        "#     start_time = max(0, last_pitch_time - (time_step * 2))  # 대략적인 범위 설정\n",
        "\n",
        "#     return start_time, last_pitch_time\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "def get_last_syllable_times(sound_path, time_step=0.01, pitch_floor=75, pitch_ceiling=500):\n",
        "    try:\n",
        "        # 음성 파일 로드\n",
        "        y, sr = librosa.load(sound_path, sr=None)\n",
        "\n",
        "        # onset_env는 음성에서 발음이 시작되는 지점 탐지\n",
        "        onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
        "\n",
        "        # 피치 계산: piptrack은 각 시간 단계에서 피치를 추출\n",
        "        pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
        "\n",
        "        # 각 타임스탬프에서 가장 강한 피치를 추출\n",
        "        pitch_values = [pitches[i, mag.argmax()] for i, mag in enumerate(magnitudes.T) if mag.any()]\n",
        "\n",
        "        if not pitch_values:\n",
        "            print(f\"No valid pitch data for {sound_path}\")\n",
        "            return None, None\n",
        "\n",
        "        # 피치가 존재하는 데이터의 시간 범위를 계산\n",
        "        pitch_times = librosa.frames_to_time(range(len(pitch_values)), sr=sr, hop_length=1024)\n",
        "\n",
        "        # 피치 값이 0인 곳을 NaN으로 처리\n",
        "        pitch_values = np.array(pitch_values)\n",
        "        pitch_values[pitch_values == 0] = np.nan\n",
        "\n",
        "        # 유효한 피치 값의 인덱스\n",
        "        valid_idx = ~np.isnan(pitch_values)\n",
        "\n",
        "        # 유효한 피치 값이 없으면 처리하지 않음\n",
        "        if valid_idx.sum() == 0:\n",
        "            print(f\"Not enough valid pitch data for {sound_path}\")\n",
        "            return None, None\n",
        "\n",
        "        # 유효한 피치 범위 계산\n",
        "        valid_pitch_times = pitch_times[valid_idx]\n",
        "        valid_pitch_values = pitch_values[valid_idx]\n",
        "\n",
        "        # 마지막 유효한 피치 데이터의 시간 범위\n",
        "        last_syllable_end = valid_pitch_times[-1]  # 마지막 유효 피치 시간\n",
        "        last_syllable_start = valid_pitch_times[0]  # 첫 번째 유효 피치 시간\n",
        "\n",
        "        # 마지막 음절의 끝을 유효한 피치 범위로 설정\n",
        "        if last_syllable_end > valid_pitch_times[-1]:\n",
        "            last_syllable_end = valid_pitch_times[-1]\n",
        "\n",
        "        return last_syllable_start, last_syllable_end\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {sound_path}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def calculate_pitch_slope(pitch_times, pitch_values, start_time, end_time):\n",
        "    \"\"\"\n",
        "    피치 구간의 기울기를 계산.\n",
        "    \"\"\"\n",
        "    within_range = (pitch_times >= start_time) & (pitch_times <= end_time)\n",
        "    segment_times = pitch_times[within_range]\n",
        "    segment_values = pitch_values[within_range]\n",
        "\n",
        "    # 에러: NaN 값 제거 코드 추가\n",
        "    valid_indices = ~np.isnan(segment_values)\n",
        "    segment_times = segment_times[valid_indices]\n",
        "    segment_values = segment_values[valid_indices]\n",
        "\n",
        "    if len(segment_times) < 2 or len(segment_values) < 2:\n",
        "        return None, None, \"Insufficient data\"  # 유효한 데이터가 부족한 경우 처리\n",
        "\n",
        "    # if len(segment_times) < 2 or np.isnan(segment_values).all():\n",
        "    #     return None, None, \"Insufficient data\"\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(segment_times.reshape(-1, 1), segment_values)\n",
        "    slope = model.coef_[0]\n",
        "    return slope, segment_values, \"Slope calculated\" # 일단 모델 뺌\n",
        "\n",
        "\n",
        "\n",
        "def annotate_intonation(slope, segment_values, full_pitch_values, rise_threshold=0.5, flat_threshold=0.1):\n",
        "    \"\"\"\n",
        "    피치 기울기를 기반으로 억양 주석을 생성.\n",
        "    \"\"\"\n",
        "    if slope is None:\n",
        "        return \"No annotation (insufficient data)\"\n",
        "    if slope > rise_threshold:\n",
        "        return \"H%\"\n",
        "    elif slope < -rise_threshold:\n",
        "        return \"L%\"\n",
        "    elif abs(slope) <= flat_threshold:\n",
        "        full_mean_pitch = np.nanmean(full_pitch_values)\n",
        "        segment_mean_pitch = np.nanmean(segment_values)\n",
        "        return \"H%\" if segment_mean_pitch > full_mean_pitch else \"L%\"\n",
        "    else:\n",
        "        return \"Flat\"\n",
        "\n",
        "def process_and_annotate_pitch(\n",
        "    sound_path,\n",
        "    last_phrase_start,\n",
        "    time_step=0.01,\n",
        "    pitch_floor=100,\n",
        "    pitch_ceiling=450,\n",
        "    rise_threshold=0.5,\n",
        "    flat_threshold=0.1\n",
        "):\n",
        "    \"\"\"\n",
        "    억양 주석을 생성하는 함수.\n",
        "    \"\"\"\n",
        "    sound = parselmouth.Sound(sound_path)\n",
        "    pitch = sound.to_pitch(time_step=time_step, pitch_floor=pitch_floor, pitch_ceiling=pitch_ceiling)\n",
        "    pitch_values = pitch.selected_array['frequency']\n",
        "    pitch_times = pitch.xs()\n",
        "    pitch_values[pitch_values == 0] = np.nan\n",
        "\n",
        "    valid_idx = ~np.isnan(pitch_values)\n",
        "\n",
        "    if valid_idx.sum() == 0:\n",
        "        print(f\"No valid pitch data for {sound_path}.\")\n",
        "        return None, \"No valid pitch data\"\n",
        "\n",
        "    interp_function = interp1d(\n",
        "        pitch_times[valid_idx],\n",
        "        pitch_values[valid_idx],\n",
        "        kind=\"linear\",\n",
        "        bounds_error=False,\n",
        "        fill_value=np.nan\n",
        "    )\n",
        "\n",
        "    interpolated_pitch = interp_function(pitch_times)\n",
        "\n",
        "    end_time = pitch_times[-1]  # 마지막 피치 시간\n",
        "    slope, segment_values, status = calculate_pitch_slope(pitch_times, interpolated_pitch, last_phrase_start, end_time)\n",
        "    # 모델 제외하고 받음\n",
        "\n",
        "    if slope is None : # or segment_values is None: 원래대로\n",
        "        annotation = \"No annotation (insufficient data)\"\n",
        "    else:\n",
        "        annotation = annotate_intonation(slope, segment_values, interpolated_pitch, rise_threshold, flat_threshold)\n",
        "\n",
        "    return slope, annotation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lygxewqgojGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 설정\n",
        "input_audio_dir = \"/content/extracted_audio_files\"\n",
        "input_json_dir = \"/content/extracted_labeling_files\"\n",
        "output_audio_dir = \"/content/output_wavs\"\n",
        "os.makedirs(output_audio_dir, exist_ok=True)\n",
        "\n",
        "output_csv_path = \"/content/utterance_features.csv\""
      ],
      "metadata": {
        "id": "Pfv4QeJIo6u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 발화 단위로 .wav 파일 분리 및 정보 추출\n",
        "results = []\n",
        "\n",
        "for json_file in os.listdir(input_json_dir):\n",
        "    if not json_file.endswith(\".json\"):\n",
        "        continue\n",
        "\n",
        "    with open(os.path.join(input_json_dir, json_file), \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    audio_file_name = data[\"File\"][\"FileName\"] + \".wav\"\n",
        "    audio_file_path = os.path.join(input_audio_dir, audio_file_name)\n",
        "\n",
        "    if not os.path.exists(audio_file_path):\n",
        "        print(f\"Audio file not found: {audio_file_path}\")\n",
        "        continue\n",
        "\n",
        "    y, sr = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "    for utterance in data[\"Conversation\"]:\n",
        "        try:\n",
        "            start_time = float(utterance[\"StartTime\"].replace(\",\", \"\"))\n",
        "            end_time = float(utterance[\"EndTime\"].replace(\",\", \"\"))\n",
        "        except ValueError as e:\n",
        "            print(f\"Error converting times for {utterance['TextNo']}: {e}\")\n",
        "            continue\n",
        "\n",
        "        emotion = utterance[\"SpeakerEmotionTarget\"]\n",
        "        utterance_id = utterance[\"TextNo\"]\n",
        "\n",
        "        start_sample = int(start_time * sr)\n",
        "        end_sample = int(end_time * sr)\n",
        "        y_segment = y[start_sample:end_sample]\n",
        "\n",
        "        segment_file_name = f\"{data['File']['FileName']}_{utterance_id}.wav\"\n",
        "        segment_file_path = os.path.join(output_audio_dir, segment_file_name)\n",
        "        sf.write(segment_file_path, y_segment, sr)\n",
        "\n",
        "        last_syllable_start, last_syllable_end = get_last_syllable_times(segment_file_path)\n",
        "        if last_syllable_start is not None and last_syllable_end is not None:\n",
        "            print(f\"{segment_file_path}: Last syllable time range is from {last_syllable_start:.2f}s to {last_syllable_end:.2f}s\")\n",
        "        else:\n",
        "            print(f\"{segment_file_path}: Skipped due to insufficient pitch data.\")\n",
        "\n",
        "\n",
        "\n",
        "        if last_syllable_start is None or last_syllable_end is None:\n",
        "            print(f\"Skipping {segment_file_name} due to insufficient data.\")\n",
        "            continue\n",
        "\n",
        "        slope, annotation = process_and_annotate_pitch(segment_file_path, last_phrase_start=last_syllable_start)\n",
        "        results.append({\n",
        "            \"ID\": segment_file_name,\n",
        "            \"emotion\": emotion,\n",
        "            \"last_syllable_start_time\": last_syllable_start,\n",
        "            \"last_syllable_end_time\": last_syllable_end,\n",
        "            \"pitch_slope\": slope,\n",
        "            \"intonation_annotation\": annotation\n",
        "        })\n",
        "\n",
        "# 결과를 DataFrame으로 저장 및 CSV로 내보내기\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"처리가 완료되었습니다. 결과는 {output_csv_path}에 저장되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U2joXAUSo4rO",
        "outputId": "f4ab46ef-d9e9-412c-86eb-ef8f027222f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000001.wav: index 39 is out of bounds for axis 1 with size 39\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000001.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000001.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000002.wav: index 69 is out of bounds for axis 1 with size 42\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000002.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000002.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000003.wav: index 481 is out of bounds for axis 1 with size 41\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000003.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000003.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000004.wav: index 126 is out of bounds for axis 1 with size 31\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000004.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000004.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000005.wav: index 137 is out of bounds for axis 1 with size 122\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000005.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000005.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000006.wav: index 72 is out of bounds for axis 1 with size 56\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000006.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000006.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000007.wav: index 89 is out of bounds for axis 1 with size 39\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000007.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000007.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000008.wav: index 75 is out of bounds for axis 1 with size 58\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000008.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000008.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000009.wav: index 85 is out of bounds for axis 1 with size 80\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000009.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000009.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000010.wav: index 60 is out of bounds for axis 1 with size 33\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000010.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000010.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000011.wav: index 450 is out of bounds for axis 1 with size 158\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000011.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000011.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000012.wav: index 127 is out of bounds for axis 1 with size 122\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000012.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000012.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000013.wav: index 74 is out of bounds for axis 1 with size 64\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000013.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000013.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000014.wav: index 117 is out of bounds for axis 1 with size 50\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000014.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000014.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000015.wav: index 410 is out of bounds for axis 1 with size 61\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000015.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000015.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000016.wav: index 135 is out of bounds for axis 1 with size 69\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000016.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000016.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000017.wav: index 266 is out of bounds for axis 1 with size 162\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000017.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000017.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000018.wav: index 132 is out of bounds for axis 1 with size 106\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000018.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000018.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000019.wav: index 153 is out of bounds for axis 1 with size 87\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000019.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000019.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000020.wav: index 511 is out of bounds for axis 1 with size 59\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000020.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000020.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000021.wav: index 148 is out of bounds for axis 1 with size 39\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000021.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000021.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000022.wav: index 229 is out of bounds for axis 1 with size 39\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000022.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000022.wav due to insufficient data.\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000023.wav: Last syllable time range is from 1.60s to 7.42s\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000024.wav: index 49 is out of bounds for axis 1 with size 33\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000024.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000024.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000025.wav: index 75 is out of bounds for axis 1 with size 73\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000025.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000025.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000026.wav: index 127 is out of bounds for axis 1 with size 98\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000026.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000026.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000027.wav: index 67 is out of bounds for axis 1 with size 31\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000027.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000027.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000028.wav: index 76 is out of bounds for axis 1 with size 47\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000028.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000028.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000029.wav: index 468 is out of bounds for axis 1 with size 100\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000029.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000029.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000030.wav: index 324 is out of bounds for axis 1 with size 120\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000030.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000030.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000031.wav: index 324 is out of bounds for axis 1 with size 42\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000031.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000031.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000032.wav: index 51 is out of bounds for axis 1 with size 31\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000032.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000032.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000033.wav: index 125 is out of bounds for axis 1 with size 94\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000033.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000033.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000034.wav: index 128 is out of bounds for axis 1 with size 31\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000034.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000034.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000035.wav: index 134 is out of bounds for axis 1 with size 119\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000035.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000035.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000036.wav: index 229 is out of bounds for axis 1 with size 34\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000036.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000036.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000037.wav: index 419 is out of bounds for axis 1 with size 125\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000037.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000037.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000038.wav: index 403 is out of bounds for axis 1 with size 144\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000038.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000038.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000039.wav: index 405 is out of bounds for axis 1 with size 31\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000039.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000039.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000040.wav: index 241 is out of bounds for axis 1 with size 142\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000040.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000040.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000041.wav: index 126 is out of bounds for axis 1 with size 59\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000041.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000041.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000042.wav: index 401 is out of bounds for axis 1 with size 353\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000042.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000042.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000043.wav: index 380 is out of bounds for axis 1 with size 81\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000043.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000043.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000044.wav: index 124 is out of bounds for axis 1 with size 117\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000044.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000044.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000045.wav: index 65 is out of bounds for axis 1 with size 53\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000045.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000045.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000046.wav: index 208 is out of bounds for axis 1 with size 164\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000046.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000046.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000047.wav: index 150 is out of bounds for axis 1 with size 47\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000047.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000047.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000048.wav: index 117 is out of bounds for axis 1 with size 111\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000048.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000048.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000049.wav: index 85 is out of bounds for axis 1 with size 72\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000049.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000049.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000050.wav: index 510 is out of bounds for axis 1 with size 156\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000050.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000050.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000051.wav: index 256 is out of bounds for axis 1 with size 101\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000051.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000051.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000052.wav: index 87 is out of bounds for axis 1 with size 53\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000052.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000052.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000053.wav: index 111 is out of bounds for axis 1 with size 36\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000053.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000053.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000054.wav: index 153 is out of bounds for axis 1 with size 142\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000054.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000054.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000055.wav: index 500 is out of bounds for axis 1 with size 197\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000055.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000055.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000056.wav: index 67 is out of bounds for axis 1 with size 58\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000056.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000056.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000057.wav: index 433 is out of bounds for axis 1 with size 397\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000057.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000057.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000058.wav: index 168 is out of bounds for axis 1 with size 141\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000058.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000058.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000059.wav: index 243 is out of bounds for axis 1 with size 117\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000059.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000059.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000060.wav: index 217 is out of bounds for axis 1 with size 103\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000060.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000060.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000061.wav: index 246 is out of bounds for axis 1 with size 164\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000061.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000061.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000062.wav: index 122 is out of bounds for axis 1 with size 51\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000062.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000062.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000063.wav: index 235 is out of bounds for axis 1 with size 134\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000063.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000063.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000064.wav: index 67 is out of bounds for axis 1 with size 59\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000064.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000064.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000065.wav: index 246 is out of bounds for axis 1 with size 181\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000065.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000065.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000066.wav: index 332 is out of bounds for axis 1 with size 159\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000066.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000066.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000067.wav: index 252 is out of bounds for axis 1 with size 164\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000067.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000067.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000068.wav: index 99 is out of bounds for axis 1 with size 53\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000068.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000068.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000069.wav: index 73 is out of bounds for axis 1 with size 69\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000069.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000069.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000070.wav: index 200 is out of bounds for axis 1 with size 114\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000070.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000070.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000071.wav: index 65 is out of bounds for axis 1 with size 33\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000071.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000071.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000072.wav: index 59 is out of bounds for axis 1 with size 31\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000072.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000072.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000073.wav: index 173 is out of bounds for axis 1 with size 31\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000073.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000073.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000074.wav: index 492 is out of bounds for axis 1 with size 122\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000074.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000074.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000075.wav: index 68 is out of bounds for axis 1 with size 47\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000075.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000075.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000076.wav: index 505 is out of bounds for axis 1 with size 76\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000076.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000076.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000077.wav: index 126 is out of bounds for axis 1 with size 123\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000077.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000077.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000078.wav: index 327 is out of bounds for axis 1 with size 61\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000078.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000078.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000079.wav: index 327 is out of bounds for axis 1 with size 89\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000079.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000079.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000080.wav: index 110 is out of bounds for axis 1 with size 72\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000080.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000080.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000081.wav: index 76 is out of bounds for axis 1 with size 76\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000081.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000081.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000082.wav: index 120 is out of bounds for axis 1 with size 116\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000082.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000082.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000083.wav: index 74 is out of bounds for axis 1 with size 45\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000083.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000083.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000084.wav: index 92 is out of bounds for axis 1 with size 62\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000084.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000084.wav due to insufficient data.\n",
            "Error processing /content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000085.wav: index 242 is out of bounds for axis 1 with size 147\n",
            "/content/output_wavs/2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000085.wav: Skipped due to insufficient pitch data.\n",
            "Skipping 2_1397G1A4_1398G2A6_T1_2D02T0062C000696_005160_000085.wav due to insufficient data.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-cfc1a18ceab9>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_segment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mlast_syllable_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_syllable_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_last_syllable_times\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlast_syllable_start\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlast_syllable_end\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{segment_file_path}: Last syllable time range is from {last_syllable_start:.2f}s to {last_syllable_end:.2f}s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-d7626fb73091>\u001b[0m in \u001b[0;36mget_last_syllable_times\u001b[0;34m(sound_path, time_step, pitch_floor, pitch_ceiling)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# 피치 계산: piptrack은 각 시간 단계에서 피치를 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mpitches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnitudes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpiptrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# 각 타임스탬프에서 가장 강한 피치를 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/pitch.py\u001b[0m in \u001b[0;36mpiptrack\u001b[0;34m(y, sr, S, n_fft, hop_length, fmin, fmax, threshold, win_length, window, center, pad_mode, ref)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;31m# then restrict to the feasible range (fmin:fmax)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mshift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parabolic_interpolation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;31m# this will get us the interpolated peak value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0mdskew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/pitch.py\u001b[0m in \u001b[0;36m_parabolic_interpolation\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# Call the vectorized stencil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0m_pi_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshiftsi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;31m# Handle the edge condition not covered by the stencil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# call the underlying gufunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frozen\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"out\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;31m# If \"out\" argument is supplied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/output_wavs/2_1377G2A2_1376G2A2_T1_2D09T0417C000394_004992_000387.wav\"\n",
        "if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
        "    print(f\"{file_path} is valid\")\n",
        "else:\n",
        "    print(f\"{file_path} is empty or does not exist\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE1qmK6uv-qX",
        "outputId": "3ebbfc29-9630-433a-e278-ca794ea9b053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/output_wavs/2_1377G2A2_1376G2A2_T1_2D09T0417C000394_004992_000387.wav is valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 마지막 어절/음절 duration 추출 -whisper word timestemp\n",
        "### 1) 마지막 어절\n",
        "\n",
        "- whisper/notebooks/Multilingual_ASR.ipynb\n",
        "  https://github.com/openai/whisper/blob/main/notebooks/Multilingual_ASR.ipynb\n",
        "\n",
        "- whisperX\n",
        "\n",
        "  https://github.com/m-bain/whisperX\n",
        "  \n",
        "  [참고] https://jellyfishdeveloper.tistory.com/entry/Whisper%EC%97%90-%EB%8B%A8%EC%96%B4%EB%B3%84-%ED%83%80%EC%9E%84%EC%8A%A4%ED%83%AC%ED%94%84%EA%B0%80-%ED%95%84%EC%9A%94%ED%95%A0-%EB%95%8C-whisperX-or-whisper-timestamped\n",
        "\n",
        "### 2) 마지막 음절 -> 마지막 pitch 구간으로 대체\n",
        "\n",
        "### 3) 어절과 억양, 그리고 태도\n",
        "(1) \"한국어 억양의 형태와 기능에 관한 연구\", 이영근\n",
        "- 청각상 구분이 어려운 태도들 사이에는 억양형태의 유사성이 있음\n",
        "- 억양형태뿐 아니라 평균주파수, 길이, 주파수폭 등도 이들 태도들의 구분에 관여하고 있으므로 이 세 요소에 의해서 억양형태만으로는 구분이 어려운 태도들을 구분할 수 있음\n",
        "\n",
        "(2) 그렇다면, pitch contour의 pitch slope뿐 아니라 평균주파수, 길이, 주파수폭, 이 세 요소를 특징 벡터로 넣어 주었을 때의 모델 성능 추이를 확인해볼 필요가 있음\n",
        "\n",
        "-> 통계를 돌려서 각 요소를 특정 기준을 두고 구간을 나누거나 도색하여, 이미지로 넣어주면 어떨까? (인간 인지 수준에서의 class 별 차이를 색깔 지정을 통해 특징으로 넣어주는 느낌...)"
      ],
      "metadata": {
        "id": "PsD_AlV97rqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-i8rmtUIAyNb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5wVMQtSQyb5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 음운구와 음절 수, 그리고 억양\n",
        "(2) \"한국어 음운구 억양 유형의 변별적 특성과 변이 조건에 대한 연구: 형태소 경계의 영향을 중심으로\", 오재혁\n",
        "- 음절 수가 많을수록 낮게 시작하는 음운구에서는 음운구의 30% 지점의 음높이가 높아지고, 높게 시작하는 음운구에서는 음운구의 70% 지점의 음높이가 낮아진다. 한편 이처럼 음절 수 구성에 따라 영향을 받는 지점의 음높이 변이는 음절 수 구성보다 분절음 종류에 의한 영향이 더 앞선다."
      ],
      "metadata": {
        "id": "E-QDZdcQEmjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. column 추가: 전체 pitch 기울기, 시간 프레임별 억양\n",
        "- 발화 내 전체 pitch 기울기 값 추출\n",
        "- 각 시간 프레임에 대한 억양 주석(rising, falling)"
      ],
      "metadata": {
        "id": "FMdVNN9227F0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPHXUTa6zjhW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 1. CSV 파일 로드\n",
        "csv_file_path = '/content/filtered_train.csv'\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# 새로운 폴더 경로 지정\n",
        "output_folder = '/content/with_features'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 2. pitch 기울기 추출 및 억양 주석 달기\n",
        "def extract_pitch_and_intonation(file_path):\n",
        "    try:\n",
        "        # librosa로 .wav 파일 로드\n",
        "        y, sr = librosa.load(file_path)\n",
        "\n",
        "        # Pitch 추출: librosa의 pitch 추정 함수 사용 (음성의 주파수 추정)\n",
        "        pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
        "\n",
        "        # 각 시간 프레임에서 가장 높은 pitch를 추출\n",
        "        pitch = []\n",
        "        for t in range(pitches.shape[1]):\n",
        "            index = magnitudes[:, t].argmax()\n",
        "            pitch.append(pitches[index, t])\n",
        "\n",
        "        # pitch 기울기 계산\n",
        "        pitch = np.array(pitch)\n",
        "        pitch_slope = np.gradient(pitch)  # 기울기 추출\n",
        "\n",
        "        # 억양 주석: pitch 변화량이 큰 부분을 강조\n",
        "        peaks, _ = find_peaks(pitch_slope, height=0.1)  # 임계값은 조정 가능\n",
        "        intonation_annotation = ['rising' if i in peaks else 'falling' for i in range(len(pitch_slope))]\n",
        "\n",
        "        return pitch_slope, intonation_annotation\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return [], []\n",
        "\n",
        "# 3. 각 파일에 대해 pitch 기울기와 억양 주석 추가\n",
        "segment_pitch_slopes = []\n",
        "segment_intonation_annotations = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    # row['path']의 ./train을 /content/train_data로 변환\n",
        "    file_path = row['path'].replace('./train', '/content/train_data')\n",
        "    print(f\"Processing: {file_path}\")  # 확인용 출력 (필요 시 제거)\n",
        "\n",
        "    # pitch 기울기와 억양 주석 추출\n",
        "    pitch_slope, intonation_annotation = extract_pitch_and_intonation(file_path)\n",
        "\n",
        "    # 리스트에 추가\n",
        "    segment_pitch_slopes.append(pitch_slope)\n",
        "    segment_intonation_annotations.append(intonation_annotation)\n",
        "\n",
        "# 4. 새로운 컬럼을 기존 DataFrame에 추가\n",
        "df['segment_pitch_slope'] = segment_pitch_slopes\n",
        "df['segment_intonation_annotations'] = segment_intonation_annotations\n",
        "\n",
        "# 5. 새로운 .csv 파일로 저장\n",
        "output_csv_path = os.path.join(output_folder, 'train_data_with_pitch_and_intonation.csv')\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"새로운 데이터가 {output_csv_path}에 저장되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sb0wC-wE1B6S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}